{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad01f20-e60b-43b6-90b4-92374f8b946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc0933c7-61ed-4d6c-9363-6741c156e337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/19 14:35:06 WARN Utils: Your hostname, data-taipei resolves to a loopback address: 127.0.1.1; using 192.168.1.43 instead (on interface ens18)\n",
      "24/03/19 14:35:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/19 14:35:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"spark_practice\")\\\n",
    "    .config(\"spark.driver.extraClassPath\", r\"/home/data-taipei/pythonHarry/mysql-connector-j-8.2.0/mysql-connector-j-8.2.0.jar\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f4fd27-866d-4014-b0e1-ee7a4a1531f6",
   "metadata": {},
   "source": [
    "# read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29893f13-4124-4b2c-9908-08648df91ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name   age\n",
       "0   Harry    25\n",
       "1  Steven    28\n",
       "2   David    27"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e16aef3-d503-4f8e-bb74-cc8aed980fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.43:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark_practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0d1f9004c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e476957-c9e6-4dbd-b6ec-a081a68fad3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, age: double, experience: double]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inferSchema=True for numeric type. Otherwise the default is all string\n",
    "df_pyspark = spark.read.option('header', 'true').csv('test.csv', inferSchema=True)\n",
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a5f57b7-9220-44a6-a7c7-3ff78080fb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+\n",
      "|  name| age|experience|\n",
      "+------+----+----------+\n",
      "| Harry|25.0|       5.0|\n",
      "|Steven|28.0|      10.0|\n",
      "| David|27.0|       7.0|\n",
      "+------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92599dcd-b63a-4654-9d65-7a978e7c3421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8265e643-c639-433a-a471-ba8fa39ec63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Harry', age=25.0, experience=5.0),\n",
       " Row(name='Steven', age=28.0, experience=10.0),\n",
       " Row(name='David', age=27.0, experience=7.0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf041f13-2d5a-4f37-b72f-2b9c14cdfc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- experience: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e548f66-baeb-4aac-ad37-c55df9e96f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- experience: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# another way for header parameter\n",
    "spark.read.csv('test.csv', inferSchema=True, header=True).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1251fae2-25e6-45cb-895a-94f4f24a69e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'age', 'experience']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get column names\n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f1f844b-c1de-40df-9c02-e1478c671300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  name|\n",
      "+------+\n",
      "| Harry|\n",
      "|Steven|\n",
      "| David|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select only name column\n",
    "df_pyspark.select('name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b16ba9e-42e2-413d-9056-a3efa32c2495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|  name|experience|\n",
      "+------+----------+\n",
      "| Harry|       5.0|\n",
      "|Steven|      10.0|\n",
      "| David|       7.0|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['name', 'experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a077b79-9304-418e-b2a8-44cab3f37198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+-----------------+\n",
      "|summary|  name|               age|       experience|\n",
      "+-------+------+------------------+-----------------+\n",
      "|  count|     3|                 3|                3|\n",
      "|   mean|  NULL|26.666666666666668|7.333333333333333|\n",
      "| stddev|  NULL|1.5275252316519468|2.516611478423583|\n",
      "|    min| David|              25.0|              5.0|\n",
      "|    max|Steven|              28.0|             10.0|\n",
      "+-------+------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a66863-0ec1-4854-8664-47f5a3fffa6e",
   "metadata": {},
   "source": [
    "# add column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b11bc33-e30c-42c4-ab75-15a9a761f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumn('experience_after_2_years', df_pyspark['experience'] + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f16d086f-6cd0-431d-8960-ceaeb4d54769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------------------------+\n",
      "|  name| age|experience|experience_after_2_years|\n",
      "+------+----+----------+------------------------+\n",
      "| Harry|25.0|       5.0|                     7.0|\n",
      "|Steven|28.0|      10.0|                    12.0|\n",
      "| David|27.0|       7.0|                     9.0|\n",
      "+------+----+----------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d38a8-e0d4-477a-a23f-323433367363",
   "metadata": {},
   "source": [
    "# drop column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "495b5f6e-1b0c-4380-8f77-fae734c65c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.drop('experience_after_2_years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b26db4c-a614-4b2b-9b31-1268d0472d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+\n",
      "|  name| age|experience|\n",
      "+------+----+----------+\n",
      "| Harry|25.0|       5.0|\n",
      "|Steven|28.0|      10.0|\n",
      "| David|27.0|       7.0|\n",
      "+------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0173e52f-50ee-4ad7-9faf-91e15f8fd077",
   "metadata": {},
   "source": [
    "# rename column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34979bc6-ec0f-48ff-8793-95d5a2d07b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----------+\n",
      "|first_name| age|experience|\n",
      "+----------+----+----------+\n",
      "|     Harry|25.0|       5.0|\n",
      "|    Steven|28.0|      10.0|\n",
      "|     David|27.0|       7.0|\n",
      "+----------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumnRenamed('name', 'first_name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a34d0-c294-4c4d-be1a-63add2371902",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "38257e58-4d3e-4844-b11e-431e6c6daab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-------+\n",
      "|   name| age|experience| salary|\n",
      "+-------+----+----------+-------+\n",
      "|  Harry|25.0|       5.0|50000.0|\n",
      "| Steven|28.0|      10.0|70000.0|\n",
      "|  David|27.0|       7.0|60000.0|\n",
      "| Andrew|NULL|       4.0|60000.0|\n",
      "|Charlie|24.0|      NULL|   NULL|\n",
      "+-------+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('test.csv', header=True, inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a1d25757-c769-464a-b13b-a73c44dfd9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+-------+\n",
      "|  name| age|experience| salary|\n",
      "+------+----+----------+-------+\n",
      "| Harry|25.0|       5.0|50000.0|\n",
      "|Steven|28.0|      10.0|70000.0|\n",
      "| David|27.0|       7.0|60000.0|\n",
      "+------+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop whole row if has any null\n",
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac548b31-f104-456a-a1d3-6fddf9b7e197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-------+\n",
      "|   name| age|experience| salary|\n",
      "+-------+----+----------+-------+\n",
      "|  Harry|25.0|       5.0|50000.0|\n",
      "| Steven|28.0|      10.0|70000.0|\n",
      "|  David|27.0|       7.0|60000.0|\n",
      "| Andrew|NULL|       4.0|60000.0|\n",
      "|Charlie|24.0|      NULL|   NULL|\n",
      "+-------+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53368e26-1089-444a-a1b3-1d763ee1cba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+-------+\n",
      "|  name| age|experience| salary|\n",
      "+------+----+----------+-------+\n",
      "| Harry|25.0|       5.0|50000.0|\n",
      "|Steven|28.0|      10.0|70000.0|\n",
      "| David|27.0|       7.0|60000.0|\n",
      "|Andrew|NULL|       4.0|60000.0|\n",
      "+------+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold\n",
    "df_pyspark.na.drop(how='any', thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df0dac8d-7883-45d4-9945-988a6d939e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-------+\n",
      "|   name| age|experience| salary|\n",
      "+-------+----+----------+-------+\n",
      "|  Harry|25.0|       5.0|50000.0|\n",
      "| Steven|28.0|      10.0|70000.0|\n",
      "|  David|27.0|       7.0|60000.0|\n",
      "|Charlie|24.0|      NULL|   NULL|\n",
      "+-------+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# subset\n",
    "df_pyspark.na.drop(how='any', subset=['age']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bc1e26-8e26-41b5-83e1-8f431c21399f",
   "metadata": {},
   "source": [
    "## fill na values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e4c79905-6c38-48c4-bec6-20ea625132b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-------+\n",
      "|   name| age|experience| salary|\n",
      "+-------+----+----------+-------+\n",
      "|  Harry|25.0|       5.0|50000.0|\n",
      "| Steven|28.0|      10.0|70000.0|\n",
      "|  David|27.0|       7.0|60000.0|\n",
      "| Andrew| 0.0|       4.0|60000.0|\n",
      "|Charlie|24.0|      NULL|    0.0|\n",
      "+-------+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill(0, ['age', 'salary']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "441f0f3c-6eec-49d3-a165-c941b5458f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['age','experience','salary'],\n",
    "    outputCols=[f'{i}_filled' for i in ['age','experience','salary']]\n",
    ").setStrategy('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "80dee175-32a8-482d-8f00-f681b8f45933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-------+----------+-----------------+-------------+\n",
      "|   name| age|experience| salary|age_filled|experience_filled|salary_filled|\n",
      "+-------+----+----------+-------+----------+-----------------+-------------+\n",
      "|  Harry|25.0|       5.0|50000.0|      25.0|              5.0|      50000.0|\n",
      "| Steven|28.0|      10.0|70000.0|      28.0|             10.0|      70000.0|\n",
      "|  David|27.0|       7.0|60000.0|      27.0|              7.0|      60000.0|\n",
      "| Andrew|NULL|       4.0|60000.0|      26.0|              4.0|      60000.0|\n",
      "|Charlie|24.0|      NULL|   NULL|      24.0|              6.5|      60000.0|\n",
      "+-------+----+----------+-------+----------+-----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc99153-b4ca-4249-8413-74c9b7458f0a",
   "metadata": {},
   "source": [
    "# filter operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e8979b0a-bdff-4190-9db1-159afd3d1d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+-------+\n",
      "| name| age|experience| salary|\n",
      "+-----+----+----------+-------+\n",
      "|Harry|25.0|       5.0|50000.0|\n",
      "+-----+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter('salary <= 50000').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c080889-69ee-4b0d-835d-d5e2ae131595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-------+\n",
      "|   name| age|experience| salary|\n",
      "+-------+----+----------+-------+\n",
      "|  Harry|25.0|       5.0|50000.0|\n",
      "|Charlie|24.0|      NULL|   NULL|\n",
      "+-------+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter((df_pyspark['salary']<=50000) | (df_pyspark['age']<=25)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d070b39d-2292-418b-a9fe-57c118aaf270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+-------+\n",
      "|  name| age|experience| salary|\n",
      "+------+----+----------+-------+\n",
      "|Steven|28.0|      10.0|70000.0|\n",
      "| David|27.0|       7.0|60000.0|\n",
      "+------+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(~(df_pyspark['experience']<=5)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388887d2-379b-4c65-b5d6-76db681ab290",
   "metadata": {},
   "source": [
    "# group by and aggredate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "936a88ef-071a-495f-a507-c8cbe9b00f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---------------+-----------+\n",
      "|team|avg(age)|avg(experience)|avg(salary)|\n",
      "+----+--------+---------------+-----------+\n",
      "|data|    26.0|            6.5|    60000.0|\n",
      "+----+--------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, sum, avg, count\n",
    "\n",
    "df_pyspark = df_pyspark.withColumn('team', lit('data'))\n",
    "df_pyspark.groupBy('team').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "84689853-2c2c-467f-b7c1-c9c46784deaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| age|count|\n",
      "+----+-----+\n",
      "|NULL|    1|\n",
      "|25.0|    1|\n",
      "|28.0|    1|\n",
      "|27.0|    1|\n",
      "|24.0|    1|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('age').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "72caba27-574c-413a-8546-e5bed1df2f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-------+------------+\n",
      "|team|sum_salary|avg_age|count_people|\n",
      "+----+----------+-------+------------+\n",
      "|data|  240000.0|   26.0|           5|\n",
      "+----+----------+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('team').agg(sum(\"salary\").alias(\"sum_salary\"),\n",
    "                               avg(\"age\").alias(\"avg_age\"),\n",
    "                               count(\"name\").alias(\"count_people\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a205e00-6798-4234-ac1f-ace9f0cc6885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
